from fastapi import FastAPI
import gradio as gr
from transformers import pipeline
import tempfile
import os

# ===== Mod√®le Whisper =====
pipe = pipeline(
    "automatic-speech-recognition",
    model="openai/whisper-tiny"
)

# Cr√©er dossier temporaire
TMP_DIR = "/tmp"
os.makedirs(TMP_DIR, exist_ok=True)

# ===== Fonction principale =====
def transcrire_audio(file):
    """
    file : fichier audio/vid√©o
    """
    result = pipe(file.name, return_timestamps=True)
    chunks = result.get("chunks", [])
    text = " ".join(chunk.get("text", "") for chunk in chunks)

    tmp_txt = tempfile.NamedTemporaryFile(delete=False, suffix=".txt")
    with open(tmp_txt.name, "w", encoding="utf-8") as f:
        f.write(text)

    return text, tmp_txt.name

# ===== Gradio UI =====
with gr.Blocks(title="Whisper Cloud Transcription") as demo:
    gr.Markdown("## üéôÔ∏è Transcription Audio / Vid√©o (Cloud HF)")
    media_input = gr.File(label="D√©pose un fichier audio ou vid√©o", file_types=["audio","video"])
    btn = gr.Button("Lancer")
    output_text = gr.Textbox(label="R√©sultat", lines=10)
    output_file = gr.File(label="T√©l√©charger le fichier texte")
    btn.click(transcrire_audio, inputs=media_input, outputs=[output_text, output_file])

# ===== Cr√©er FastAPI et monter Gradio =====
app = FastAPI()
app = gr.mount_gradio_app(app, demo, path="/")  # Gradio disponible √† la racine
